{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Loading GloVe, this might take a few (10~30) seconds... -- \n",
      "\n",
      "... Done, processed 45 messages\n",
      "... Done, processed 185 messages\n",
      "... Done, processed 185 messages\n",
      "... Done, processed 196 messages\n",
      "... Done, processed 259 messages\n",
      "... Done, processed 310 messages\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "NLP_PATH = '/'.join(os.path.abspath('.').split('/')[:-1]) + '/'\n",
    "sys.path.append(NLP_PATH)\n",
    "from nlp.text import extractor as xt\n",
    "from nlp.models.message_classification import SimpleClassifier\n",
    "from nlp.utils.model_output_management import OutputHelper\n",
    "from nlp.models.similarity_calculation import MessageSimilarity\n",
    "from nlp.models.summarization import TFIDF\n",
    "from nlp.grammar import tokenizer as nt\n",
    "from nlp.viz.cloud import Wordcloud\n",
    "from nlp.viz import graph as vg\n",
    "\n",
    "casdb = xt.CassandraExtractor(cluster_ips=['54.175.189.47'],\n",
    "                              session_keyspace='test_keyspace',\n",
    "                              table_name='awaybot_messages')\n",
    "channels = ['general']\n",
    "msg_sim = MessageSimilarity()\n",
    "FONT_PATH = '../nlp/data/font/Ranga-Regular.ttf'\n",
    "IMG_FOLDER = '../nlp/data/img/'\n",
    "viz_topics = 0\n",
    "for channel in channels:\n",
    "    for p in xrange(1, 7,1):\n",
    "        min_topic_length = 5 if p < 2 else 10\n",
    "        msg_stream = casdb.get_messages(type_of_query='week', periods=p, channel=channel, min_words=5)\n",
    "        classifier = SimpleClassifier(message_similarity=msg_sim)\n",
    "        classified_window = classifier.classify_stream(\n",
    "            msg_stream, low_threshold=.4, high_threshold=.7, low_step=.05, high_step=.02,\n",
    "            max_messages=10000, verbose=False)\n",
    "        if len(classified_window) == 0:\n",
    "            continue\n",
    "        n_model = TFIDF(classified_window, cleaner=nt.SimpleCleaner(), n_grams=5)\n",
    "        for t, topic in enumerate(classified_window):\n",
    "            if len(topic) >= min_topic_length:\n",
    "                viz_topics += 1\n",
    "                viz = vg.Wordgraph(n_model, document_id=t, max_words=8)\n",
    "                viz_path = IMG_FOLDER + 'graph_topic_{}_{}_{}_{}.png'.format(channel, 'weeks', p, viz_topics)\n",
    "                viz.save_png(viz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Loading GloVe, this might take a few (10~30) seconds... -- \n",
      "\n",
      "... Done, processed 185 messages\n",
      "... Done, processed 185 messages\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "NLP_PATH = '/'.join(os.path.abspath('.').split('/')[:-1]) + '/'\n",
    "sys.path.append(NLP_PATH)\n",
    "from nlp.text import extractor as xt\n",
    "from nlp.models.message_classification import SimpleClassifier\n",
    "from nlp.utils.model_output_management import OutputHelper\n",
    "from nlp.models.similarity_calculation import MessageSimilarity\n",
    "from nlp.models.summarization import TFIDF\n",
    "from nlp.grammar import tokenizer as nt\n",
    "from nlp.viz.cloud import Wordcloud\n",
    "from nlp.viz import graph as vg\n",
    "team = 'Slack-pack'\n",
    "channel = 'general'\n",
    "\n",
    "\n",
    "casdb = xt.CassandraExtractor(cluster_ips=['54.175.189.47'],\n",
    "                              session_keyspace='test_keyspace',\n",
    "                              table_name='awaybot_messages')\n",
    "channels = ['general']\n",
    "msg_sim = MessageSimilarity()\n",
    "FONT_PATH = '../nlp/data/font/Ranga-Regular.ttf'\n",
    "IMG_FOLDER = '../nlp/data/img/'\n",
    "viz_topics = 0\n",
    "for p in xrange(2,4):\n",
    "    msg_stream = casdb.get_messages(type_of_query='week', periods=p, channel=channel, min_words=5)\n",
    "    classifier = SimpleClassifier(message_similarity=msg_sim)\n",
    "    classified_window = classifier.classify_stream(msg_stream, low_threshold=.4, high_threshold=.7, low_step=.05, high_step=.02, max_messages=10000, verbose=False)\n",
    "    image_loader = OutputHelper()\n",
    "    if len(classified_window) == 0:\n",
    "        image_loader.updateImageCount(team, channel, p, 'weeks')\n",
    "\n",
    "    else:\n",
    "        # Create a model using the corpus\n",
    "        uni_model = TFIDF(window=classified_window, cleaner=nt.SimpleCleaner(), n_grams=4)\n",
    "        # bigram_model = Model(window=classified_window, cleaner=nt.SimpleCleaner(), n_grams=2)  # if we wanted a bigram model\n",
    "\n",
    "        viz_topics = 0\n",
    "        for t, topic in enumerate(classified_window):  # one(?) per topic\n",
    "            if len(topic) >= 10:\n",
    "                viz = vg.Wordgraph(model=uni_model, document_id=t, max_words=4)\n",
    "                viz_path = IMG_FOLDER + 'graph_topic_{}_{}_{}_{}.png'.format(channel, 'weeks', p, viz_topics)\n",
    "                viz.save_png(viz_path)\n",
    "                viz_topics += 1\n",
    "\n",
    "                # Call image_loader with: img_path + starter_message_url + team + channel + duration + duration_unit\n",
    "                image_loader.add_viz(viz_path, topic.start_message.url, topic.start_message.team, channel, p, 'weeks')\n",
    "                # TODO: parameter-ize the duration unit\n",
    "    #     if viz_topics:\n",
    "    #         image_loader.upload()\n",
    "    #     else:\n",
    "    #         # Create a sdb item that records '0' images for that particular channel and duration\n",
    "    #         image_loader.updateImageCount(team, channel, p, 'weeks')\n",
    "        # logger.info(\n",
    "        #     'Updloaded {} Images for channel {} and '\n",
    "        #     'duration: {} {}'.format(viz_topics, channel, p, 'week(s)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
